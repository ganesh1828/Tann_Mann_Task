{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e8229905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "def show_image(img):\n",
    "    cv.imshow(\"Image\", img)\n",
    "    cv.waitKey(0)\n",
    "\n",
    "def draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels):\n",
    "    # If there are any detections\n",
    "    file1 = open('cordinate.txt', 'w')\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            # Get the bounding box coordinates\n",
    "            x, y = boxes[i][0], boxes[i][1]\n",
    "            w, h = boxes[i][2], boxes[i][3]\n",
    "            \n",
    "            # Get the unique color for this class\n",
    "            color = [int(c) for c in colors[classids[i]]]\n",
    "            outcor=str(labels[classids[i]])+\" \"+str(confidences[i])+\" \"+str(x)+\" \"+str(y)+\" \"+str(w)+\" \"+str(h)+\"\\n\"\n",
    "            print(outcor)\n",
    "            file1.write(outcor)\n",
    "            # Draw the bounding box rectangle and label on the image\n",
    "            cv.rectangle(img, (x, y), (x+w, y+h), color, 2)\n",
    "            text = \"{}: {:4f}\".format(labels[classids[i]], confidences[i])\n",
    "            cv.putText(img, text, (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "    file1.close()\n",
    "    return img\n",
    "\n",
    "\n",
    "def generate_boxes_confidences_classids(outs, height, width, tconf):\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classids = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            #print (detection)\n",
    "            #a = input('GO!')\n",
    "            \n",
    "            # Get the scores, classid, and the confidence of the prediction\n",
    "            scores = detection[5:]\n",
    "            classid = np.argmax(scores)\n",
    "            confidence = scores[classid]\n",
    "            \n",
    "            # Consider only the predictions that are above a certain confidence level\n",
    "            if confidence > tconf:\n",
    "                # TODO Check detection\n",
    "                box = detection[0:4] * np.array([width, height, width, height])\n",
    "                centerX, centerY, bwidth, bheight = box.astype('int')\n",
    "\n",
    "                # Using the center x, y coordinates to derive the top\n",
    "                # and the left corner of the bounding box\n",
    "                x = int(centerX - (bwidth / 2))\n",
    "                y = int(centerY - (bheight / 2))\n",
    "\n",
    "                # Append to list\n",
    "                boxes.append([x, y, int(bwidth), int(bheight)])\n",
    "                confidences.append(float(confidence))\n",
    "                classids.append(classid)\n",
    "\n",
    "    return boxes, confidences, classids\n",
    "\n",
    "def infer_image(net, layer_names, height, width, img, colors, labels, FLAGS, \n",
    "            boxes=None, confidences=None, classids=None, idxs=None, infer=True):\n",
    "    \n",
    "    if infer:\n",
    "        # Contructing a blob from the input image\n",
    "        blob = cv.dnn.blobFromImage(img, 1 / 255.0, (416, 416), \n",
    "                        swapRB=True, crop=False)\n",
    "\n",
    "        # Perform a forward pass of the YOLO object detector\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Getting the outputs from the output layers\n",
    "        start = time.time()\n",
    "        outs = net.forward(layer_names)\n",
    "        end = time.time()\n",
    "\n",
    "        if FLAGS.show_time:\n",
    "            print (\"[INFO] YOLOv3 took {:6f} seconds\".format(end - start))\n",
    "\n",
    "        \n",
    "        # Generate the boxes, confidences, and classIDs\n",
    "        boxes, confidences, classids = generate_boxes_confidences_classids(outs, height, width, FLAGS.confidence)\n",
    "        \n",
    "        # Apply Non-Maxima Suppression to suppress overlapping bounding boxes\n",
    "        idxs = cv.dnn.NMSBoxes(boxes, confidences, FLAGS.confidence, FLAGS.threshold)\n",
    "\n",
    "    if boxes is None or confidences is None or idxs is None or classids is None:\n",
    "        raise '[ERROR] Required variables are set to None before drawing boxes on images.'\n",
    "        \n",
    "    # Draw labels and boxes on the image\n",
    "    img = draw_labels_and_boxes(img, boxes, confidences, classids, idxs, colors, labels)\n",
    "    \n",
    "    return img, boxes, confidences, classids, idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7812824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9f5a490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog 0.9979028701782227 122 223 197 320\n",
      "\n",
      "bicycle 0.990092396736145 117 124 452 307\n",
      "\n",
      "truck 0.9369485378265381 472 86 219 79\n",
      "\n",
      "Ouput Image Expored in Output folder\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2 as cv\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "FLAGS = []\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\n",
    "\tparser.add_argument('-m', '--model-path',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/',\n",
    "\t\thelp='The directory where the model weights and \\\n",
    "\t\t\t  configuration files are.')\n",
    "\n",
    "\tparser.add_argument('-w', '--weights',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/yolov3.weights',\n",
    "\t\thelp='Path to the file which contains the weights \\\n",
    "\t\t\t \tfor YOLOv3.')\n",
    "\n",
    "\tparser.add_argument('-cfg', '--config',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/yolov3.cfg',\n",
    "\t\thelp='Path to the configuration file for the YOLOv3 model.')\n",
    "\n",
    "\tparser.add_argument('-i', '--image-path',\n",
    "\t\ttype=str,\n",
    "\t\thelp='The path to the image file')\n",
    "\n",
    "\tparser.add_argument('-v', '--video-path',\n",
    "\t\ttype=str,\n",
    "\t\thelp='The path to the video file')\n",
    "\n",
    "\n",
    "\tparser.add_argument('-vo', '--video-output-path',\n",
    "\t\ttype=str,\n",
    "        default='./output.avi',\n",
    "\t\thelp='The path of the output video file')\n",
    "\n",
    "\tparser.add_argument('-l', '--labels',\n",
    "\t\ttype=str,\n",
    "\t\tdefault='./yolov3-coco/coco-labels',\n",
    "\t\thelp='Path to the file having the \\\n",
    "\t\t\t\t\tlabels in a new-line seperated way.')\n",
    "\n",
    "\tparser.add_argument('-c', '--confidence',\n",
    "\t\ttype=float,\n",
    "\t\tdefault=0.5,\n",
    "\t\thelp='The model will reject boundaries which has a \\\n",
    "\t\t\t\tprobabiity less than the confidence value. \\\n",
    "\t\t\t\tdefault: 0.5')\n",
    "\n",
    "\tparser.add_argument('-th', '--threshold',\n",
    "\t\ttype=float,\n",
    "\t\tdefault=0.3,\n",
    "\t\thelp='The threshold to use when applying the \\\n",
    "\t\t\t\tNon-Max Suppresion')\n",
    "\n",
    "\tparser.add_argument('--download-model',\n",
    "\t\ttype=bool,\n",
    "\t\tdefault=False,\n",
    "\t\thelp='Set to True, if the model weights and configurations \\\n",
    "\t\t\t\tare not present on your local machine.')\n",
    "\n",
    "\tparser.add_argument('-t', '--show-time',\n",
    "\t\ttype=bool,\n",
    "\t\tdefault=False,\n",
    "\t\thelp='Show the time taken to infer each image.')\n",
    "\n",
    "\tFLAGS, unparsed = parser.parse_known_args()\n",
    "\n",
    "\t# Download the YOLOv3 models if needed\n",
    "\tif FLAGS.download_model:\n",
    "\t\tsubprocess.call(['./yolov3-coco/get_model.sh'])\n",
    "\n",
    "\t# Get the labels\n",
    "\tlabels = open(FLAGS.labels).read().strip().split('\\n')\n",
    "\n",
    "\t# Intializing colors to represent each label uniquely\n",
    "\tcolors = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')\n",
    "\n",
    "\t# Load the weights and configutation to form the pretrained YOLOv3 model\n",
    "\tnet = cv.dnn.readNetFromDarknet(FLAGS.config, FLAGS.weights)\n",
    "\n",
    "\t# Get the output layer names of the model\n",
    "\tlayer_names = net.getLayerNames()\n",
    "\tlayer_names = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        \n",
    "\n",
    "\timg = cv.imread(\"InputFiles/dog.jpg\")\n",
    "\theight, width = img.shape[:2]\n",
    "\t\n",
    "\n",
    "\t\t\n",
    "\timg,boxes, confidences, classids, idxs = infer_image(net, layer_names, height, width, img, colors, labels, FLAGS)\n",
    "\t#show_image(img)\n",
    "\n",
    "\tcv.imwrite(\"output/predicion.jpg\",img)\n",
    "\tprint(\"Ouput Image Expored in Output folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d485a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
